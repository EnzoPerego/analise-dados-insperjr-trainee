{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo Preditivo - Tempo de Entrega (ETA)\n",
        "Notebook para criar modelo preditivo que melhore a estimativa de tempo de entrega.\n",
        "\n",
        "**Objetivo:** Melhorar a precisão da estimativa de tempo de entrega (`eta_minutes_quote`) apenas para pedidos dos canais próprios (site_proprio + whatsapp).\n",
        "\n",
        "**Metodologia:** Divisão train/test dupla, cross-validation e comparação de 5 modelos usando RMSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup e Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 481,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurações visuais\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
        "plt.rcParams[\"axes.grid\"] = True\n",
        "plt.rcParams[\"font.size\"] = 10\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carregamento dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados carregados:\n",
            "   • Total de registros: 5,000\n",
            "   • Colunas: 16\n",
            "   • Valores nulos: 0\n",
            "\n",
            "Colunas disponíveis:\n",
            "['macro_bairro', 'nome_cliente', 'bairro_destino', 'order_datetime', 'platform', 'order_mode', 'distance_km', 'tempo_preparo_minutos', 'status', 'eta_minutes_quote', 'actual_delivery_minutes', 'total_brl', 'classe_pedido', 'platform_commission_pct', 'num_itens', 'satisfacao_nivel']\n"
          ]
        }
      ],
      "source": [
        "# Carregar dados limpos\n",
        "df = pd.read_csv(\"../tratamento_inicial/Base_Kaiserhaus_Limpa.csv\")\n",
        "\n",
        "print(\"Dados carregados:\")\n",
        "print(f\"   • Total de registros: {len(df):,}\")\n",
        "print(f\"   • Colunas: {df.shape[1]}\")\n",
        "print(f\"   • Valores nulos: {df.isnull().sum().sum()}\")\n",
        "\n",
        "print(\"\\nColunas disponíveis:\")\n",
        "print(list(df.columns))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Filtro para Canais Próprios\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar apenas canais próprios\n",
        "df_canais_proprios = df.copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering e One-Hot Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['order_datetime'] = pd.to_datetime(df['order_datetime'])\n",
        "\n",
        "df['hora_pedido'] = df['order_datetime'].dt.hour\n",
        "df['dia_semana'] = df['order_datetime'].dt.day_name()\n",
        "df['is_weekend'] = df['order_datetime'].dt.weekday >= 5\n",
        "\n",
        "# Criar período do dia baseado nos insights (horários críticos identificados)\n",
        "def categorizar_periodo_dia(hora):\n",
        "    if 6 <= hora < 12:\n",
        "        return 'Manhã'\n",
        "    elif 12 <= hora < 18:\n",
        "        return 'Tarde'\n",
        "    elif 18 <= hora < 24:\n",
        "        return 'Noite'\n",
        "    else:\n",
        "        return 'Madrugada'\n",
        "\n",
        "df['periodo_dia'] = df['hora_pedido'].apply(categorizar_periodo_dia)\n",
        "\n",
        "# aqui seriia a criacao de features baseadas nos insights\n",
        "\n",
        "# sazonalidade diária\n",
        "df['hora_sin'] = np.sin(2 * np.pi * df['hora_pedido'] / 24)\n",
        "df['hora_cos'] = np.cos(2 * np.pi * df['hora_pedido'] / 24)\n",
        "\n",
        "# flags para cenários críticos identificados na análise\n",
        "df['is_horario_critico'] = df['hora_pedido'].isin([18, 19, 20, 21, 22, 23]).astype(int)\n",
        "df['is_plataforma_critica'] = (df['platform'] == 'ifood').astype(int)\n",
        "df['is_bairro_critico'] = df['macro_bairro'].isin(['Morumbi', 'Vila Mariana', 'Santo Amaro']).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FEATURE ENGINEERING COMPLETO\n",
            "==================================================\n",
            "Arquivo: 'base_modelo_preditivo_eta.csv'\n",
            "Total de registros: 5,000\n",
            "Colunas: 19\n",
            "Features categóricas criadas: 15\n",
            "\n",
            "Distribuição por período do dia:\n",
            "   • Tarde: 1,897 pedidos (37.9%)\n",
            "   • Noite: 1,569 pedidos (31.4%)\n",
            "   • Manhã: 1,399 pedidos (28.0%)\n",
            "   • Madrugada: 135 pedidos (2.7%)\n"
          ]
        }
      ],
      "source": [
        "# Função para obter período do dia\n",
        "def obter_periodo_dia(hora):\n",
        "    if 0 <= hora < 6:\n",
        "        return 'Madrugada'\n",
        "    elif 6 <= hora < 12:\n",
        "        return 'Manhã'\n",
        "    elif 12 <= hora < 18:\n",
        "        return 'Tarde'\n",
        "    else:\n",
        "        return 'Noite'\n",
        "    \n",
        "def obter_dia_semana(data):\n",
        "    return pd.to_datetime(data).dt.day_name()\n",
        "\n",
        "# Criar dia da semana no DataFrame\n",
        "df_canais_proprios['dia_semana'] = obter_dia_semana(df_canais_proprios['order_datetime'])\n",
        "\n",
        "# Criar período do dia diretamente no DataFrame\n",
        "df_canais_proprios['periodo_dia'] = pd.to_datetime(df_canais_proprios['order_datetime']).dt.hour.apply(obter_periodo_dia)\n",
        "\n",
        "# Selecionar features\n",
        "features_numericas = ['distance_km', 'tempo_preparo_minutos', 'num_itens']\n",
        "features_categoricas = ['periodo_dia', 'platform', 'dia_semana']\n",
        "target = 'actual_delivery_minutes'\n",
        "\n",
        "# Criar DataFrames separados\n",
        "X_numericas = df_canais_proprios[features_numericas].copy()\n",
        "X_categoricas = df_canais_proprios[features_categoricas].copy()\n",
        "y = df_canais_proprios[target].copy()\n",
        "\n",
        "# Aplicar One-Hot Encoding nas colunas categóricas SEM remover nenhuma categoria\n",
        "encoder = OneHotEncoder(sparse_output=False, drop=None)\n",
        "X_categoricas_encoded = encoder.fit_transform(X_categoricas)\n",
        "\n",
        "# Criar DataFrame com nomes das colunas\n",
        "feature_names = encoder.get_feature_names_out(features_categoricas)\n",
        "X_categoricas_df = pd.DataFrame(X_categoricas_encoded, columns=feature_names, index=X_categoricas.index)\n",
        "\n",
        "# Combinar features numéricas e categóricas\n",
        "X_intermediario = pd.concat([X_numericas, X_categoricas_df], axis=1)\n",
        "\n",
        "# features adicionais baseadas nos insights\n",
        "X_insights = df[['hora_sin', 'hora_cos', \n",
        "                 'is_horario_critico', 'is_plataforma_critica', 'is_bairro_critico']].copy()\n",
        "\n",
        "#comobinar as features X\n",
        "X_final = pd.concat([X_intermediario, X_insights], axis=1)\n",
        "\n",
        "# Salvar base com One-Hot Encoding aplicado\n",
        "df_base_final = pd.concat([df_canais_proprios[features_numericas + ['actual_delivery_minutes']], X_categoricas_df], axis=1)\n",
        "df_base_final.to_csv(\"base_modelo_preditivo_eta.csv\", index=False)\n",
        "\n",
        "print(\"FEATURE ENGINEERING COMPLETO\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Arquivo: 'base_modelo_preditivo_eta.csv'\")\n",
        "print(f\"Total de registros: {len(df_base_final):,}\")\n",
        "print(f\"Colunas: {df_base_final.shape[1]}\")\n",
        "print(f\"Features categóricas criadas: {len(feature_names)}\")\n",
        "\n",
        "print(\"\\nDistribuição por período do dia:\")\n",
        "distribuicao_periodo = df_canais_proprios['periodo_dia'].value_counts()\n",
        "for periodo, count in distribuicao_periodo.items():\n",
        "    pct = count / len(df_canais_proprios) * 100\n",
        "    print(f\"   • {periodo}: {count:,} pedidos ({pct:.1f}%)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Divisão Train/Test Dupla e Modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TESTE INICIAL - TODOS OS MODELOS\n",
            "=======================================================\n",
            "Dummy Regressor (Mean)    → RMSE Treino = 12.632 | RMSE Teste = 12.739\n",
            "Linear Regression (Pipeline) → RMSE Treino = 5.494 | RMSE Teste = 5.550\n",
            "Decision Tree (Default)   → RMSE Treino = 0.015 | RMSE Teste = 7.784\n",
            "Decision Tree (10)        → RMSE Treino = 4.928 | RMSE Teste = 6.193\n",
            "Decision Tree (15)        → RMSE Treino = 2.849 | RMSE Teste = 7.436\n",
            "Random Forest (100)       → RMSE Treino = 4.400 | RMSE Teste = 5.745\n",
            "Random Forest (200)       → RMSE Treino = 4.392 | RMSE Teste = 5.734\n",
            "Random Forest (500)       → RMSE Treino = 4.392 | RMSE Teste = 5.733\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# 1️⃣ Split único (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_final, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# 2️⃣ Split Duplo (80/20) - Validação interna\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# 3️⃣ Definir modelos\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "modelos = {\n",
        "    # Dummy Regressor - variações\n",
        "    'Dummy Regressor (Mean)': DummyRegressor(strategy='mean'),\n",
        "    \n",
        "    # Linear Regression - variações\n",
        "    'Linear Regression (Pipeline)': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('regressor', LinearRegression())\n",
        "    ]),\n",
        "    \n",
        "    # Decision Tree - variações\n",
        "    'Decision Tree (Default)': DecisionTreeRegressor(random_state=42),\n",
        "    'Decision Tree (10)': DecisionTreeRegressor(\n",
        "        max_depth=10, \n",
        "        min_samples_split=20, \n",
        "        min_samples_leaf=10, \n",
        "        random_state=42\n",
        "    ),\n",
        "    'Decision Tree (15)': DecisionTreeRegressor(\n",
        "        max_depth=15, \n",
        "        min_samples_split=5, \n",
        "        min_samples_leaf=2, \n",
        "        random_state=42\n",
        "    ),\n",
        "    \n",
        "    # Random Forest - variações\n",
        "    'Random Forest (100)': RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'Random Forest (200)': RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=10,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'Random Forest (500)': RandomForestRegressor(\n",
        "        n_estimators=500,\n",
        "        max_depth=10,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42\n",
        "    ),\n",
        "}\n",
        "\n",
        "# 4️⃣ TESTAR TODOS OS MODELOS NO SPLIT PRINCIPAL\n",
        "print(\"TESTE INICIAL - TODOS OS MODELOS\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "resultados_iniciais = {}\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    modelo.fit(X_train, y_train)\n",
        "    \n",
        "    # Previsões\n",
        "    y_pred_train = modelo.predict(X_train)\n",
        "    y_pred_test = modelo.predict(X_test)\n",
        "    \n",
        "    # Cálculo de RMSE\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    \n",
        "    resultados_iniciais[nome] = {\n",
        "        'RMSE Treino': rmse_train,\n",
        "        'RMSE Teste': rmse_test,\n",
        "    }\n",
        "    \n",
        "    print(f\"{nome:25s} → RMSE Treino = {rmse_train:.3f} | RMSE Teste = {rmse_test:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 487,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "VALIDAÇÃO FINAL - APENAS Random Forest (100)\n",
            "============================================================\n",
            "RMSE Treino (Split 2): 4.442\n",
            "RMSE Teste (Split 2): 5.369\n",
            "\n",
            "COMPARAÇÃO FINAL:\n",
            "========================================\n",
            "RMSE Teste (Split 1): 5.745\n",
            "RMSE Teste (Split 2): 5.369\n",
            "Diferença: 0.376\n"
          ]
        }
      ],
      "source": [
        "# 5️⃣ ESCOLHER O MELHOR MODELO\n",
        "melhor_modelo_nome = ('Random Forest (100)')\n",
        "# 6️⃣ TESTAR APENAS O MELHOR MODELO NO SPLIT DUPLO\n",
        "print(f\"\\nVALIDAÇÃO FINAL - APENAS {melhor_modelo_nome}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Obter o modelo escolhido\n",
        "melhor_modelo = modelos[melhor_modelo_nome]\n",
        "\n",
        "# Teste no split duplo\n",
        "melhor_modelo.fit(X_train_2, y_train_2)\n",
        "y_pred_train_2 = melhor_modelo.predict(X_train_2)\n",
        "y_pred_test_2 = melhor_modelo.predict(X_test_2)\n",
        "\n",
        "# RMSE no split duplo\n",
        "rmse_train_2 = np.sqrt(mean_squared_error(y_train_2, y_pred_train_2))\n",
        "rmse_test_2 = np.sqrt(mean_squared_error(y_test_2, y_pred_test_2))\n",
        "\n",
        "print(f\"RMSE Treino (Split 2): {rmse_train_2:.3f}\")\n",
        "print(f\"RMSE Teste (Split 2): {rmse_test_2:.3f}\")\n",
        "\n",
        "# 7️⃣ COMPARAÇÃO FINAL\n",
        "print(f\"\\nCOMPARAÇÃO FINAL:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"RMSE Teste (Split 1): {resultados_iniciais[melhor_modelo_nome]['RMSE Teste']:.3f}\")\n",
        "print(f\"RMSE Teste (Split 2): {rmse_test_2:.3f}\")\n",
        "\n",
        "# Verificar consistência\n",
        "diferenca = abs(resultados_iniciais[melhor_modelo_nome]['RMSE Teste'] - rmse_test_2)\n",
        "print(f\"Diferença: {diferenca:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Comparacao com ETA antigo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " COMPARAÇÃO ETA ANTIGO vs NOVO vs ACTUAL\n",
            "============================================================\n",
            "\n",
            " ESTATÍSTICAS GERAIS:\n",
            "   • RMSE ETA Antigo: 12.179\n",
            "   • RMSE ETA Novo: 4.466\n",
            "   • Melhoria: 63.3%\n",
            "\n",
            " EXEMPLOS DE MELHORIA:\n",
            "Pedido   ETA Antigo   ETA Novo     Actual       Erro Antigo  Erro Novo   \n",
            "--------------------------------------------------------------------------------\n",
            "1.0      50.0         63.8         62.4         12.4         1.4         \n",
            "2.0      45.0         37.4         35.6         9.4          1.8         \n",
            "3.0      43.0         31.9         34.5         8.5          2.6         \n",
            "4.0      19.0         12.2         14.4         4.6          2.2         \n",
            "6.0      44.0         35.4         33.5         10.5         1.9         \n",
            "7.0      44.0         29.8         36.5         7.5          6.7         \n",
            "8.0      40.0         31.5         34.5         5.5          3.0         \n",
            "9.0      29.0         22.2         19.9         9.1          2.3         \n",
            "11.0     29.0         12.4         7.2          21.8         5.2         \n",
            "12.0     47.0         41.2         38.2         8.8          3.0         \n",
            "\n",
            " EXEMPLOS DE PIORA:\n",
            "Pedido   ETA Antigo   ETA Novo     Actual       Erro Antigo  Erro Novo   \n",
            "--------------------------------------------------------------------------------\n",
            "5.0      28.0         29.4         26.6         1.4          2.8         \n",
            "10.0     47.0         46.5         48.6         1.6          2.1         \n",
            "20.0     47.0         51.9         46.6         0.4          5.3         \n",
            "21.0     42.0         37.1         42.0         0.0          4.9         \n",
            "32.0     34.0         31.9         38.0         4.0          6.1         \n",
            "38.0     21.0         13.2         32.7         11.7         19.5        \n",
            "40.0     49.0         45.5         47.4         1.6          1.9         \n",
            "47.0     39.0         43.0         40.3         1.3          2.7         \n",
            "48.0     40.0         31.7         36.6         3.4          4.9         \n",
            "55.0     52.0         46.3         53.0         1.0          6.7         \n",
            "\n",
            " RESUMO:\n",
            "   • Pedidos com melhoria: 4124 (82.5%)\n",
            "   • Pedidos com piora: 876 (17.5%)\n",
            "   • Pedidos iguais: 0 (0.0%)\n"
          ]
        }
      ],
      "source": [
        "# COMPARAÇÃO ETA ANTIGO vs NOVO vs ACTUAL\n",
        "print(\" COMPARAÇÃO ETA ANTIGO vs NOVO vs ACTUAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Usar o melhor modelo (Random Forest 500)\n",
        "melhor_modelo = modelos['Random Forest (100)']\n",
        "melhor_modelo.fit(X_final, y)\n",
        "\n",
        "# Fazer predições\n",
        "eta_novo = melhor_modelo.predict(X_final)\n",
        "\n",
        "# Criar DataFrame de comparação\n",
        "comparacao = pd.DataFrame({\n",
        "    'Pedido': range(1, len(df_canais_proprios) + 1),\n",
        "    'ETA_Antigo': df_canais_proprios['eta_minutes_quote'].values,\n",
        "    'ETA_Novo': eta_novo,\n",
        "    'Actual_Delivery': df_canais_proprios['actual_delivery_minutes'].values\n",
        "})\n",
        "\n",
        "# Calcular diferenças\n",
        "comparacao['Diff_Antigo'] = comparacao['Actual_Delivery'] - comparacao['ETA_Antigo']\n",
        "comparacao['Diff_Novo'] = comparacao['Actual_Delivery'] - comparacao['ETA_Novo']\n",
        "\n",
        "# Calcular erros absolutos\n",
        "comparacao['Erro_Abs_Antigo'] = abs(comparacao['Diff_Antigo'])\n",
        "comparacao['Erro_Abs_Novo'] = abs(comparacao['Diff_Novo'])\n",
        "\n",
        "# Estatísticas gerais\n",
        "print(f\"\\n ESTATÍSTICAS GERAIS:\")\n",
        "print(f\"   • RMSE ETA Antigo: {np.sqrt(mean_squared_error(comparacao['Actual_Delivery'], comparacao['ETA_Antigo'])):.3f}\")\n",
        "print(f\"   • RMSE ETA Novo: {np.sqrt(mean_squared_error(comparacao['Actual_Delivery'], comparacao['ETA_Novo'])):.3f}\")\n",
        "print(f\"   • Melhoria: {((np.sqrt(mean_squared_error(comparacao['Actual_Delivery'], comparacao['ETA_Antigo'])) - np.sqrt(mean_squared_error(comparacao['Actual_Delivery'], comparacao['ETA_Novo']))) / np.sqrt(mean_squared_error(comparacao['Actual_Delivery'], comparacao['ETA_Antigo'])) * 100):.1f}%\")\n",
        "\n",
        "# Mostrar alguns exemplos de melhoria\n",
        "print(f\"\\n EXEMPLOS DE MELHORIA:\")\n",
        "melhorias = comparacao[comparacao['Erro_Abs_Novo'] < comparacao['Erro_Abs_Antigo']].head(10)\n",
        "print(f\"{'Pedido':<8} {'ETA Antigo':<12} {'ETA Novo':<12} {'Actual':<12} {'Erro Antigo':<12} {'Erro Novo':<12}\")\n",
        "print(\"-\" * 80)\n",
        "for _, row in melhorias.iterrows():\n",
        "    print(f\"{row['Pedido']:<8} {row['ETA_Antigo']:<12.1f} {row['ETA_Novo']:<12.1f} {row['Actual_Delivery']:<12.1f} {row['Erro_Abs_Antigo']:<12.1f} {row['Erro_Abs_Novo']:<12.1f}\")\n",
        "\n",
        "# Mostrar alguns exemplos de piora\n",
        "print(f\"\\n EXEMPLOS DE PIORA:\")\n",
        "pioras = comparacao[comparacao['Erro_Abs_Novo'] > comparacao['Erro_Abs_Antigo']].head(10)\n",
        "print(f\"{'Pedido':<8} {'ETA Antigo':<12} {'ETA Novo':<12} {'Actual':<12} {'Erro Antigo':<12} {'Erro Novo':<12}\")\n",
        "print(\"-\" * 80)\n",
        "for _, row in pioras.iterrows():\n",
        "    print(f\"{row['Pedido']:<8} {row['ETA_Antigo']:<12.1f} {row['ETA_Novo']:<12.1f} {row['Actual_Delivery']:<12.1f} {row['Erro_Abs_Antigo']:<12.1f} {row['Erro_Abs_Novo']:<12.1f}\")\n",
        "\n",
        "# Contar melhorias vs pioras\n",
        "melhorias_count = len(comparacao[comparacao['Erro_Abs_Novo'] < comparacao['Erro_Abs_Antigo']])\n",
        "pioras_count = len(comparacao[comparacao['Erro_Abs_Novo'] > comparacao['Erro_Abs_Antigo']])\n",
        "iguais_count = len(comparacao[comparacao['Erro_Abs_Novo'] == comparacao['Erro_Abs_Antigo']])\n",
        "\n",
        "print(f\"\\n RESUMO:\")\n",
        "print(f\"   • Pedidos com melhoria: {melhorias_count} ({melhorias_count/len(comparacao)*100:.1f}%)\")\n",
        "print(f\"   • Pedidos com piora: {pioras_count} ({pioras_count/len(comparacao)*100:.1f}%)\")\n",
        "print(f\"   • Pedidos iguais: {iguais_count} ({iguais_count/len(comparacao)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANÁLISE DETALHADA DAS PIORAS\n",
            "============================================================\n",
            "\n",
            "MELHORIAS (4124 pedidos):\n",
            "   • Erro Antigo - Média: 11.773 | Std: 6.152\n",
            "   • Erro Novo - Média: 2.991 | Std: 2.395\n",
            "   • Redução média: 8.782 min\n",
            "\n",
            "PIORAS (876 pedidos):\n",
            "   • Erro Antigo - Média: 2.892 | Std: 2.754\n",
            "   • Erro Novo - Média: 5.662 | Std: 3.560\n",
            "   • Aumento médio: 2.770 min\n"
          ]
        }
      ],
      "source": [
        "# ANÁLISE DETALHADA DAS PIORAS\n",
        "print(\"ANÁLISE DETALHADA DAS PIORAS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Separar categorias\n",
        "melhorias = comparacao[comparacao['Erro_Abs_Novo'] < comparacao['Erro_Abs_Antigo']]\n",
        "pioras = comparacao[comparacao['Erro_Abs_Novo'] > comparacao['Erro_Abs_Antigo']]\n",
        "iguais = comparacao[comparacao['Erro_Abs_Novo'] == comparacao['Erro_Abs_Antigo']]\n",
        "\n",
        "# Estatísticas das melhorias\n",
        "print(f\"\\nMELHORIAS ({len(melhorias)} pedidos):\")\n",
        "print(f\"   • Erro Antigo - Média: {melhorias['Erro_Abs_Antigo'].mean():.3f} | Std: {melhorias['Erro_Abs_Antigo'].std():.3f}\")\n",
        "print(f\"   • Erro Novo - Média: {melhorias['Erro_Abs_Novo'].mean():.3f} | Std: {melhorias['Erro_Abs_Novo'].std():.3f}\")\n",
        "print(f\"   • Redução média: {melhorias['Erro_Abs_Antigo'].mean() - melhorias['Erro_Abs_Novo'].mean():.3f} min\")\n",
        "\n",
        "# Estatísticas das pioras\n",
        "print(f\"\\nPIORAS ({len(pioras)} pedidos):\")\n",
        "print(f\"   • Erro Antigo - Média: {pioras['Erro_Abs_Antigo'].mean():.3f} | Std: {pioras['Erro_Abs_Antigo'].std():.3f}\")\n",
        "print(f\"   • Erro Novo - Média: {pioras['Erro_Abs_Novo'].mean():.3f} | Std: {pioras['Erro_Abs_Novo'].std():.3f}\")\n",
        "print(f\"   • Aumento médio: {pioras['Erro_Abs_Novo'].mean() - pioras['Erro_Abs_Antigo'].mean():.3f} min\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 490,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANÁLISE DE PADRÕES DAS PIORAS COM PERCENTUAL DE PIORAS POR FAIXA\n",
            "======================================================================\n",
            "Total de pioras: 876 pedidos\n",
            "Percentual geral: 17.5%\n",
            "\n",
            "ANÁLISE POR PLATAFORMA:\n",
            "==================================================\n",
            "Plataforma      Qtd    Total    % Pioras   Erro Antigo  Erro Novo    Distância  Preparo  Itens \n",
            "----------------------------------------------------------------------------------------------------\n",
            "ifood           427.0  2661.0   16.0       2.829        5.522        4.60       19.3     3.6   \n",
            "rappi           114.0  747.0    15.3       2.683        5.607        4.68       18.5     3.3   \n",
            "site_proprio    208.0  1052.0   19.8       2.974        5.663        2.51       18.7     3.5   \n",
            "whatsapp        127.0  540.0    23.5       3.160        6.181        0.66       17.3     3.1   \n",
            "\n",
            "ANÁLISE POR PERÍODO DO DIA:\n",
            "==================================================\n",
            "Período      Qtd    Total    % Pioras   Erro Antigo  Erro Novo    Distância  Preparo \n",
            "------------------------------------------------------------------------------------------\n",
            "Madrugada    36.0   135.0    26.7       3.358        5.754        3.26       18.7    \n",
            "Manhã        258.0  1399.0   18.4       2.920        5.835        3.60       18.9    \n",
            "Noite        264.0  1569.0   16.8       2.797        5.660        3.34       18.6    \n",
            "Tarde        318.0  1897.0   16.8       2.897        5.513        3.70       18.9    \n",
            "\n",
            "ANÁLISE POR FAIXAS DE DISTÂNCIA:\n",
            "==================================================\n",
            "Faixa    Qtd    Total    % Pioras   Erro Antigo  Erro Novo    Preparo \n",
            "----------------------------------------------------------------------\n",
            "0-1km    256.0  1300.0   19.7       3.088        5.857        17.9    \n",
            "1-2km    43.0   318.0    13.5       2.621        5.199        22.5    \n",
            "2-3km    51.0   464.0    11.0       2.784        5.777        19.7    \n",
            "3-5km    231.0  1324.0   17.4       3.137        6.261        18.9    \n",
            "5+km     292.0  1582.0   18.5       2.589        5.074        18.9    \n",
            "\n",
            "⏱ANÁLISE POR FAIXAS DE TEMPO DE PREPARO:\n",
            "==================================================\n",
            "Faixa      Qtd    Total    % Pioras   Erro Antigo  Erro Novo    Distância \n",
            "--------------------------------------------------------------------------------\n",
            "0-15min    290.0  2589.0   11.2       3.546        7.218        3.39      \n",
            "15-25min   449.0  1780.0   25.2       2.432        4.837        3.70      \n",
            "25-35min   124.0  500.0    24.8       2.689        4.533        3.40      \n",
            "35+min     13.0   131.0    9.9        6.175        10.231       3.16      \n"
          ]
        }
      ],
      "source": [
        "# ANÁLISE DE PADRÕES DAS PIORAS COM PERCENTUAL DE PIORAS POR FAIXA\n",
        "print(\"ANÁLISE DE PADRÕES DAS PIORAS COM PERCENTUAL DE PIORAS POR FAIXA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Separar pioras\n",
        "pioras = comparacao[comparacao['Erro_Abs_Novo'] > comparacao['Erro_Abs_Antigo']]\n",
        "\n",
        "print(f\"Total de pioras: {len(pioras)} pedidos\")\n",
        "print(f\"Percentual geral: {len(pioras)/len(comparacao)*100:.1f}%\")\n",
        "\n",
        "# Adicionar informações da plataforma às pioras\n",
        "pioras_com_info = pioras.copy()\n",
        "pioras_com_info['platform'] = df_canais_proprios.loc[pioras.index, 'platform'].values\n",
        "pioras_com_info['periodo_dia'] = df_canais_proprios.loc[pioras.index, 'periodo_dia'].values\n",
        "pioras_com_info['distance_km'] = df_canais_proprios.loc[pioras.index, 'distance_km'].values\n",
        "pioras_com_info['tempo_preparo_minutos'] = df_canais_proprios.loc[pioras.index, 'tempo_preparo_minutos'].values\n",
        "pioras_com_info['num_itens'] = df_canais_proprios.loc[pioras.index, 'num_itens'].values\n",
        "\n",
        "#ANÁLISE POR PLATAFORMA\n",
        "print(f\"\\nANÁLISE POR PLATAFORMA:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Contar total por plataforma na base inteira\n",
        "total_por_platform = df_canais_proprios['platform'].value_counts()\n",
        "total_geral = len(df_canais_proprios)\n",
        "\n",
        "# Análise por plataforma\n",
        "platform_analysis = pioras_com_info.groupby('platform').agg({\n",
        "    'Erro_Abs_Antigo': ['count', 'mean', 'std'],\n",
        "    'Erro_Abs_Novo': ['mean', 'std'],\n",
        "    'distance_km': 'mean',\n",
        "    'tempo_preparo_minutos': 'mean',\n",
        "    'num_itens': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "platform_analysis.columns = ['Qtd_Pioras', 'Erro_Antigo_Medio', 'Erro_Antigo_Std', \n",
        "                            'Erro_Novo_Medio', 'Erro_Novo_Std', 'Distancia_Media', \n",
        "                            'Tempo_Preparo_Medio', 'Num_Itens_Medio']\n",
        "\n",
        "# Adicionar percentuais da base inteira\n",
        "platform_analysis['Total_Base'] = platform_analysis.index.map(total_por_platform)\n",
        "platform_analysis['Pct_Pioras_Da_Faixa'] = (platform_analysis['Qtd_Pioras'] / platform_analysis['Total_Base'] * 100).round(1)\n",
        "\n",
        "print(f\"{'Plataforma':<15} {'Qtd':<6} {'Total':<8} {'% Pioras':<10} {'Erro Antigo':<12} {'Erro Novo':<12} {'Distância':<10} {'Preparo':<8} {'Itens':<6}\")\n",
        "print(\"-\" * 100)\n",
        "for platform, row in platform_analysis.iterrows():\n",
        "    print(f\"{platform:<15} {row['Qtd_Pioras']:<6} {row['Total_Base']:<8} {row['Pct_Pioras_Da_Faixa']:<10} {row['Erro_Antigo_Medio']:<12.3f} {row['Erro_Novo_Medio']:<12.3f} {row['Distancia_Media']:<10.2f} {row['Tempo_Preparo_Medio']:<8.1f} {row['Num_Itens_Medio']:<6.1f}\")\n",
        "\n",
        "#ANÁLISE POR PERÍODO DO DIA\n",
        "print(f\"\\nANÁLISE POR PERÍODO DO DIA:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Contar total por período na base inteira\n",
        "total_por_periodo = df_canais_proprios['periodo_dia'].value_counts()\n",
        "\n",
        "periodo_analysis = pioras_com_info.groupby('periodo_dia').agg({\n",
        "    'Erro_Abs_Antigo': ['count', 'mean'],\n",
        "    'Erro_Abs_Novo': 'mean',\n",
        "    'distance_km': 'mean',\n",
        "    'tempo_preparo_minutos': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "periodo_analysis.columns = ['Qtd_Pioras', 'Erro_Antigo_Medio', 'Erro_Novo_Medio', \n",
        "                           'Distancia_Media', 'Tempo_Preparo_Medio']\n",
        "\n",
        "# Adicionar percentuais da base inteira\n",
        "periodo_analysis['Total_Base'] = periodo_analysis.index.map(total_por_periodo)\n",
        "periodo_analysis['Pct_Pioras_Da_Faixa'] = (periodo_analysis['Qtd_Pioras'] / periodo_analysis['Total_Base'] * 100).round(1)\n",
        "\n",
        "print(f\"{'Período':<12} {'Qtd':<6} {'Total':<8} {'% Pioras':<10} {'Erro Antigo':<12} {'Erro Novo':<12} {'Distância':<10} {'Preparo':<8}\")\n",
        "print(\"-\" * 90)\n",
        "for periodo, row in periodo_analysis.iterrows():\n",
        "    print(f\"{periodo:<12} {row['Qtd_Pioras']:<6} {row['Total_Base']:<8} {row['Pct_Pioras_Da_Faixa']:<10} {row['Erro_Antigo_Medio']:<12.3f} {row['Erro_Novo_Medio']:<12.3f} {row['Distancia_Media']:<10.2f} {row['Tempo_Preparo_Medio']:<8.1f}\")\n",
        "\n",
        "\n",
        "#ANÁLISE POR FAIXAS DE DISTÂNCIA\n",
        "print(f\"\\nANÁLISE POR FAIXAS DE DISTÂNCIA:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Criar faixas de distância\n",
        "pioras_com_info['faixa_distancia'] = pd.cut(pioras_com_info['distance_km'], \n",
        "                                           bins=[0, 1, 2, 3, 5, float('inf')], \n",
        "                                           labels=['0-1km', '1-2km', '2-3km', '3-5km', '5+km'])\n",
        "\n",
        "# Criar faixas na base inteira para comparação\n",
        "df_canais_proprios['faixa_distancia'] = pd.cut(df_canais_proprios['distance_km'], \n",
        "                                             bins=[0, 1, 2, 3, 5, float('inf')], \n",
        "                                             labels=['0-1km', '1-2km', '2-3km', '3-5km', '5+km'])\n",
        "\n",
        "total_por_distancia = df_canais_proprios['faixa_distancia'].value_counts()\n",
        "\n",
        "distancia_analysis = pioras_com_info.groupby('faixa_distancia').agg({\n",
        "    'Erro_Abs_Antigo': ['count', 'mean'],\n",
        "    'Erro_Abs_Novo': 'mean',\n",
        "    'tempo_preparo_minutos': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "distancia_analysis.columns = ['Qtd_Pioras', 'Erro_Antigo_Medio', 'Erro_Novo_Medio', 'Tempo_Preparo_Medio']\n",
        "\n",
        "# Adicionar percentuais da base inteira\n",
        "distancia_analysis['Total_Base'] = distancia_analysis.index.map(total_por_distancia).astype(int)\n",
        "distancia_analysis['Pct_Pioras_Da_Faixa'] = (distancia_analysis['Qtd_Pioras'] / distancia_analysis['Total_Base'] * 100).round(1)\n",
        "\n",
        "print(f\"{'Faixa':<8} {'Qtd':<6} {'Total':<8} {'% Pioras':<10} {'Erro Antigo':<12} {'Erro Novo':<12} {'Preparo':<8}\")\n",
        "print(\"-\" * 70)\n",
        "for faixa, row in distancia_analysis.iterrows():\n",
        "    print(f\"{faixa:<8} {row['Qtd_Pioras']:<6} {row['Total_Base']:<8} {row['Pct_Pioras_Da_Faixa']:<10} {row['Erro_Antigo_Medio']:<12.3f} {row['Erro_Novo_Medio']:<12.3f} {row['Tempo_Preparo_Medio']:<8.1f}\")\n",
        "\n",
        "#ANÁLISE POR FAIXAS DE TEMPO DE PREPARO\n",
        "print(f\"\\n⏱ANÁLISE POR FAIXAS DE TEMPO DE PREPARO:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Criar faixas de tempo de preparo\n",
        "pioras_com_info['faixa_preparo'] = pd.cut(pioras_com_info['tempo_preparo_minutos'], \n",
        "                                         bins=[0, 15, 25, 35, float('inf')], \n",
        "                                         labels=['0-15min', '15-25min', '25-35min', '35+min'])\n",
        "\n",
        "# Criar faixas na base inteira para comparação\n",
        "df_canais_proprios['faixa_preparo'] = pd.cut(df_canais_proprios['tempo_preparo_minutos'], \n",
        "                                           bins=[0, 15, 25, 35, float('inf')], \n",
        "                                           labels=['0-15min', '15-25min', '25-35min', '35+min'])\n",
        "\n",
        "total_por_preparo = df_canais_proprios['faixa_preparo'].value_counts()\n",
        "\n",
        "preparo_analysis = pioras_com_info.groupby('faixa_preparo').agg({\n",
        "    'Erro_Abs_Antigo': ['count', 'mean'],\n",
        "    'Erro_Abs_Novo': 'mean',\n",
        "    'distance_km': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "preparo_analysis.columns = ['Qtd_Pioras', 'Erro_Antigo_Medio', 'Erro_Novo_Medio', 'Distancia_Media']\n",
        "\n",
        "# Adicionar percentuais da base inteira\n",
        "preparo_analysis['Total_Base'] = preparo_analysis.index.map(total_por_preparo).astype(int)\n",
        "preparo_analysis['Pct_Pioras_Da_Faixa'] = (preparo_analysis['Qtd_Pioras'] / preparo_analysis['Total_Base'] * 100).round(1)\n",
        "\n",
        "print(f\"{'Faixa':<10} {'Qtd':<6} {'Total':<8} {'% Pioras':<10} {'Erro Antigo':<12} {'Erro Novo':<12} {'Distância':<10}\")\n",
        "print(\"-\" * 80)\n",
        "for faixa, row in preparo_analysis.iterrows():\n",
        "    print(f\"{faixa:<10} {row['Qtd_Pioras']:<6} {row['Total_Base']:<8} {row['Pct_Pioras_Da_Faixa']:<10} {row['Erro_Antigo_Medio']:<12.3f} {row['Erro_Novo_Medio']:<12.3f} {row['Distancia_Media']:<10.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
